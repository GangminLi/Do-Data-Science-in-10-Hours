[
["understand-data.html", "Chapter 4 Understand Data", " Chapter 4 Understand Data Understand your building raw materials can help you choose correct tools and make the most use of them to construct your ideal buildings. Understand data is the foundation for solving analytical problems. The two major purposes of understand data are: Access data quantity Access data quality Set up objects for data preprocess In practice the two initial data assessments can be done together or separately. The purpose of them is to setup objective for data preprocess to accomplish. The methods used to understand data can be both Descriptive analysis and Exploratory analysis. "],
["load-data.html", "4.1 Load data", " 4.1 Load data Here are my initial plan for understand Titanic data: Get Titanic data load into RStudio Assess Data quantity (number of files, size of each file in number of records, number of attributes in each record) Attributes types assessment Attributes value assessment (numbers and summary, description). Now, get your RStudio ready. If you have not done the Exercises 2.5, which asked you to create a new R project named “MyDataScienceProject”. You can do it now. Open your RStudio, Click File-&gt; New project-&gt;New Directory -&gt; choose New R Project“, then, enter”MyDataScienceProject\" in the Directory name box and select your directory. Click “Create Project” at the right bottom as shown in Figure 4.1 Figure 4.1: Create a new project in RStudio Load file “TitanicDataScience1.R” into RStudio. create a new R file and name it “MyTitanicDataScience1”. The protocol is you copy lines indicated from this tutorial “chunk” by “chunk” into your R file and run them. Okay let us start, In your RStudio (WorkSpace), copy lines from “TitanicDataScience1.R” into your file “MyTitanicDataScience1”, # Load raw data train &lt;- read.csv(&quot;train.csv&quot;, header = TRUE) test &lt;- read.csv(&quot;test.csv&quot;, header = TRUE) You will see this in your Console, &gt; train &lt;- read.csv(&quot;train.csv&quot;, header = TRUE) Error in file(file, &quot;rt&quot;) : cannot open the connection In addition: Warning message: In file(file, &quot;rt&quot;) : cannot open file &#39;train.csv&#39;: No such file or directory &gt; test &lt;- read.csv(&quot;test.csv&quot;, header = TRUE) Error in file(file, &quot;rt&quot;) : cannot open the connection In addition: Warning message: In file(file, &quot;rt&quot;) : cannot open file &#39;test.csv&#39;: No such file or directory &gt; Don’t panic. let us look into it. The first thing I want you to learn is to use RStudio help. Remember how to use it? Now type ? read.cvs in your Console, look at the Multifunction pane, the tab Help is auto selected and help message for read.cvs is appeared. See Figure 4.2 Figure 4.2: Screen capture of Error and Help Now, notice that the error message says, “cannot open file 'test.csv': No such file or directory”. We don’t have file train.csv and test.csv in our working directory. Now, Download the traon.csv and test.csv from Kaggle (if you did not download already) and stored into our project working directory1. Please note that it is a common practice that data scientist download datasets from data sources and save to a local drive. Having a local version of the raw datasets is good idea. But a lot of times, it is unfeasible to do so either because the data is too big or there are some access restriction prevent you have a local version. So, you have to using service provider’s API or data URI through HTTP protocol or other protocol like FTP etc. Once, you have download the datasets from Kaggle website and unzipped (or moved) them into your local working directory, run the same code again by select them all and click “Run” or type “Ctr + Enter” . You will see the two new attributes have been created and displayed in the WorkSpace pane. See Figure 4.3. Figure 4.3: Screen capture of import raw data Try yourself: Import data from WorkSpace pane by click “Import Dataset” button. The data files were asked to be downloaded and unzipped in the previous chapter ?? . If you simply unzip it into the working directory, it will exists in “~/Titanic/” directory. In this case, you need to move them into your working directory.↩︎ "],
["assess-data-quantity.html", "4.2 Assess Data Quantity", " 4.2 Assess Data Quantity After we have load the raw data into our WorkSpace, we can start to explore and exam the raw data. In R code, the best way to explore a dataset and get the first impression on its size (number of records and numbers of attributes) is using str() function. If you wan tot know more about it, as I mentioned earlier, using help by typing ? str() in your Console. There is an equivalent R code is called help &lt;statement&gt;, you can try help str(). Now let us run the following code, # Exam train and test datasets train &lt;- read.csv(&quot;train.csv&quot;, header = TRUE) test &lt;- read.csv(&quot;test.csv&quot;, header = TRUE) You will see this in your console, Figure 4.4. Figure 4.4: Screen capture of str(tain) and str(test) Firstly, you will see the size of the two datasets: train has 891 records and each record has 12 attributes. Okay, R uses statistics terminology, observation is record in data science term. properties of an observation are attributes of a record. Notice that train has a type of data.from. Data.frame is the most used data type in R. (Try ?data.frame to explore) test has 418 records and each record has 11 attributes, which are less than train’s in both number of records and attributes. Dataset test has less number of records makes sense because any model you need large data to train and less data to test ( it will become clear later). However, why test has one less attribute? compare with train, it is easy to find out that the missing attribute is Survived. Do you understand now? The dataset test is supposedly to be used for testing our model (we will have it later) for predicting passengers’ have lived and dead. So, it should not have a value now. The entire problem is for us to come up with a value on the attribute. RStudio has a conveniently build-in function to explore data size. At the WorkSpace pane, you can see the under Environment tab, the two attributes we have created are listed there. In font of each attribute there is a sign. click it you can exam its size and structure. It is equivalent to run str() R instruction. You can also lick on the attribute name to explore the entire dataset. Try yourself: At RStudio WorkSpace pane, Click varaible name train and test to explore the contents of datasets. Click on the sign in front of attribute to explore it sstructure. "],
["general-data-attributes-assessment.html", "4.3 General Data Attributes Assessment", " 4.3 General Data Attributes Assessment After a brief assessment on the data quantity, we know that the both datasets are not too big in terms of both number records (891 and 418) and number of attributes (12 and 11). We also have an intuitive understanding about the attributes, some obvious names like Name, Sex and Age; and some not so obvious names like SibSp and Parch. Before we looking into individual attributes (single variate analysis) in our datasets, let us get some general sense of all attributes and make sure we understand each of them. We knew that dataset test has 11 attributes and train has 12 attributes. The one attribute short is the Survived. The rest are the same. Let us look into those attributes, the following is from the Kaggel web site: Figure 4.5: Data Dectionary from Kaggle website. attribute Notes *Pclass*: A proxy for socio-economic status (SES) 1st = Upper 2nd = Middle 3rd = Lower *Age*: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5 *Sibsp*: The dataset defines family relations in this way... *Sibling* = brother, sister, stepbrother, stepsister *Spouse* = husband, wife (mistresses and fiancés were ignored) *Parch*: The dataset defines family relations in this way... Parent = mother, father Child = daughter, son, stepdaughter, stepson Some children travelled only with a nanny, therefore parch=0 for them. Just looking into these attributes’ description, a few thoughts are occurred: Attribute types There are attributes should be categorical types. The values of those attributes can be any types but the importance is that they can classify the records into sets of similar groups and this grouping make sense to the problem to be solved. In Titanic datasets, attributes should have categorical type are: Survived, Sex, Embarked, and Pclass. Other attribute perhaps should have numerical type. Thsi is because these attributes values change from record to record. They can be the values of discrete, continuous, or timeseries. One thing in common is that these values can be manipulated and applied with many math functions and plotting tools for visualization. In Titanic datasets, attributes should have numerical type are: Age, Fare, SibSp, Parch. Contribution to Survive The final goal is to predict passenger’s survived or not. It makes sense to assess the prediction power of each attribute. which is the contribution of an attribute to attrribute Survived. In other words, the potential relationships among these attributes and with the attribute Survived need to be assessed. Here are some thoughts: Pclass should somehow linked with Fare and Cabin. Generally, the higher the class is and the more expensive of the fare will be and the better cabin locations are. So those should have some sort of correlations among them. they together should have some affect on survive. You would think that the expensive ticket, means better cabin location and has privilege to escape first in the disaster. What is the ticket number to do with survive? Is it just a random number? Or is associated with cabin? Or anything else like Port of embarkation? ticket number in some other systems could have more information rather than just an unique number. Is the Fair in someways associated with journey length, which means the Port of embarkation and the port of disembarkation? Or cabin location and condition? You can have other thoughts too. To prove or disprove these assumptions and thoughts, we need to look into the actual datasets at least to see: What are the data types for various attributes? Which attributes are available in the dataset? Which attributes are categorical? Which attributes are numerical? Which attributes are mixed data types? Any errors in the attributes values? Which features may contain errors or typos? Which features contain blank, null or empty values? These questions will be answered in the following two sections. "],
["actual-attributes-types-examination.html", "4.4 Actual Attributes Types Examination", " 4.4 Actual Attributes Types Examination Since we have our raw data in RStudio, We can exam attributes’ types. From figure 4.4, we can see that all the attributes have three types, int, Factor, num. Attributes have int types are: PassengerId, Survived, SibSp, Parch. Attributes has Factor types are: Name, Sex, Ticket, Cabin and Embarked. Attributes has num types are: Age and Fare. We know that, the type int is for attribute that has an integer value; and num is for an numeric attribute, which has the values of real numbers. Type Factor is R language’s way to say category type. It is a attribute that can take on one of a limited, and usually fixed, number of possible values, such as blood type. Attributes types affect the operations we can apply on that attributes. In other words inappropriate types can prevent us to do proper analysis on that attribute. For example, it doe’s not make sense to calculate average on sex, so it is better to be with a type of Category, in R is a Factor. Similarly, Survived will have only two values 0 or 1, to represent death or live. It makes sense to be an Factor too. Being a int type, it will prevent us to apply many methods that only works for a Factor type attribute. Another example is Name, its original type is Factor to reflect on its uniqueness. However, Type “Factor” is not good for string processing. It has been prevented that to apply regular expression2 on it. So, it is appropriate to change it into chr as a character. There are other inappropriate or wrong attribute’s types too such as SibSp and Parch are currently typed int. May be they should be considered as Factor. It is a common practice that data scientists apply different analyses on a attribute and change the attribute type to apply other different algorithms again. The goal is to dig the insight out of data. So, looking into data attributes types, compare with the original meaning of each attributes can help us to spot any inappropriate types or wrong types. Thinking: Is Servived typed int approriate? What other attributes do you think are in a wrong type? A regular expression is a sequence of characters that define a search pattern, which is used by string-searching algorithms to find a particular string or validate a input string.↩︎ "],
["attvalue.html", "4.5 Actual Data Attributes Value Examination", " 4.5 Actual Data Attributes Value Examination To understand given datasets needs to carefully examine the values of each data attributes to: find any errors and missing values find value distribution find potential relation with the attribute to be predicted (also called dependent variable) Finding errors, typos and missing values can set up the goals for data prepsocess. Since the examine covers both datesets train and test, it make sense to combine the two datasets into one big dataset, so it can save us to run the same code twice on the different datasets. Copy the following code into your script, # Add a &quot;Survived&quot; attribute to the test dataset to allow for combining with train dataset test &lt;- data.frame(test[1], Survived = rep(&quot;NA&quot;, nrow(test)), test[ ,2:ncol(test)]) # Combine data sets. Append test.survived to train data &lt;- rbind(train, test) Now we have a dataset data, which combines both datasets train and test datasets. We assigned the value of attribute Survived in the original dataset test as “NA”. You can check them in the WorkSpace pane by click variable data. Thinking: Can we combine train and test without add Survived attribute to the test? Like, data &lt;- rbind(train, test) Why add attibute Survived as the second attribute? Can we add it as the first one? Like, test &lt;- data.frame(Survived = rep(\"NA\", nrow(test)), test[,]) It is good idea to have bird eye’s view on our combined dataset. # check out data with a summary summary(data) ## PassengerId Survived Pclass ## Min. : 1 Length:1309 Min. :1.000 ## 1st Qu.: 328 Class :character 1st Qu.:2.000 ## Median : 655 Mode :character Median :3.000 ## Mean : 655 Mean :2.295 ## 3rd Qu.: 982 3rd Qu.:3.000 ## Max. :1309 Max. :3.000 ## ## Name Sex Age ## Connolly, Miss. Kate : 2 female:466 Min. : 0.17 ## Kelly, Mr. James : 2 male :843 1st Qu.:21.00 ## Abbing, Mr. Anthony : 1 Median :28.00 ## Abbott, Mr. Rossmore Edward : 1 Mean :29.88 ## Abbott, Mrs. Stanton (Rosa Hunt): 1 3rd Qu.:39.00 ## Abelson, Mr. Samuel : 1 Max. :80.00 ## (Other) :1301 NA&#39;s :263 ## SibSp Parch Ticket Fare ## Min. :0.0000 Min. :0.000 CA. 2343: 11 Min. : 0.000 ## 1st Qu.:0.0000 1st Qu.:0.000 1601 : 8 1st Qu.: 7.896 ## Median :0.0000 Median :0.000 CA 2144 : 8 Median : 14.454 ## Mean :0.4989 Mean :0.385 3101295 : 7 Mean : 33.295 ## 3rd Qu.:1.0000 3rd Qu.:0.000 347077 : 7 3rd Qu.: 31.275 ## Max. :8.0000 Max. :9.000 347082 : 7 Max. :512.329 ## (Other) :1261 NA&#39;s :1 ## Cabin Embarked ## :1014 : 2 ## C23 C25 C27 : 6 C:270 ## B57 B59 B63 B66: 5 Q:123 ## G6 : 5 S:914 ## B96 B98 : 4 ## C22 C26 : 4 ## (Other) : 271 This summary tell us a lot of information. Most obvious are: PassengerID is useless in terms of predicting survived or not. in addition, it is not much help that provide a statistical summary on it. Survived and Pclass numbers are useful and interesting. Name is mostly unique, which comes a surprise that only 2 names are repeated twice. Gender distribution among passenger is unbalanced that male overweight female. Age is interesting that minimum age 0.17 is alarming and there is 263 missing values. SibSp tells us the largest relatives travel together is 8. ParCh tells us the largest family travel together is 9. There are a number of ticket has the same number. The most repeat number is CA. 2343, which has 11 duplicates. Ticket Fare shows the minimum is 0, which is interesting that someone take a free ride. The maximum is over 512, which is far too expensive when the mean value is only about 33. Cabin has a large number of missing values (identified by \"\"). Embarked only has three values which is not a good sign for prediction. it also has 2 missing value. You can see now one function can provide so much information. Quantitative summary is a great tool for a data scientist. Now, Let us exam each attribute, 4.5.1 PassengerID. PassengerId is an identifier, So only its uniqueness and missing value are considered. There are many ways you can use to find out. I simply check its total number and its unique number. If the both equal to the number of records in the dataset, it shows that there is no duplication and no missing values in the attribute. So we do, # Exam PassengerID length(data$PassengerId) ## [1] 1309 length(unique(data$PassengerId)) ## [1] 1309 The results shows the both number 1309, which is equal to the total number of records in the dataset. It proves the PassengerID has not missing value and duplication. 4.5.2 Survived Survived is the attribute that its value will be produced by a model for the dataset test. It is called Consequencer in modeling contrast with other attributes. which are used to produce a prediction, are called Predictor. So, our exam will be conducted only on dataset train. Again we can check the numbers whether they can add up or not. As we already mentioned that it makes sense to change the Servived from type chr into Factor. We do, # Exam Survived data$Survived &lt;- as.factor(data$Survived) table(data$Survived) ## ## 0 1 NA ## 549 342 418 The results proved that the Survived value has the correct numbers: 418 ‘NA’ values are the Survived’s value in the dataset test, and the 549 death and 342 survived, together maded up the total number of dataset train, which is 891. So we know the value of Survived in the dataset train are correct and has no missing values. It is interesting here to think about the survive rate. How to calculate? I will do this, # Calculate the survive rate in train data is 38% and the death rate is 61.61% prop.table(table(as.factor(train$Survived))) ## ## 0 1 ## 0.6161616 0.3838384 So we know the survive rate in the dataset train is about 61%. This is interesting because it reflects the overall survival rate. 4.5.3 Pclass Pclass is the feature which splits the passengers into three division namely class-1, class-2, class-3. As we understood it should be in type of Factor rather than int. We shall change its type first and then to see if there missing value or errors. It is also good to know the survival rate in each class. So. we can compare with the overall survival rate in the dataset train. Copy the following code into your script. # Examine Pclass value, # Look into Kaggle&#39;s explanation about Pclass: it is a proxy for social class i.e. rich or poor # It should be factor and it does not make sense to stay in int. data$Pclass &lt;- as.factor(data$Pclass) test$Pclass &lt;- as.factor(test$Pclass) train$Pclass &lt;- as.factor(train$Pclass) # Distribution across classes table(data$Pclass) ## ## 1 2 3 ## 323 277 709 If you want, you can check the total of the three classes which is 1309. It equals to the total number of records in the data (total number fo passenger). And there is no other numbers than 1,2 and 3. So we can conclude that there is no missing value and no errors in Pcalss. It will be interesting to see the survival rate for each class, # Distribution across classes with survive table(data$Pclass, data$Survived) ## ## 0 1 NA ## 1 80 136 107 ## 2 97 87 93 ## 3 372 119 218 These numbers tell us many things: The death distribution. Among the three classes from class-1 to class-3 is: 80, 97 and 379. It confirms that the passenger in Class-3 has largest number of death (372); The survival distribution. Among the three classes, class-1 has the highest number of survival (136); The passengers distribution. Among the three classes, class-3 has the largest passenger numbers (372+119+218) in total, and overtaking other two classes together for both datasets train and test (372+119) &gt; ((80+97) + (136+87)). The last column is the pasenger distribution among the three glasses for dataset test. This is because its Survived value is “NA” (not defined). We can calculate distributions among the three classes in terms of percentage. The overall passenger’s distribution among the three classes: # Calculate the distribution on Pclass # Overall passenger distribution on classes. prop.table(table(as.factor(data$Pclass))) ## ## 1 2 3 ## 0.2467532 0.2116119 0.5416348 That is 24.67% passenger in Class-1, 21.16% passenger is class-2 and 54.16% of passenger in class-3. The passenger’s distribution among the three classes given by dataset train: # Train data passenger distribution on classes. prop.table(table(as.factor(train$Pclass))) ## ## 1 2 3 ## 0.2424242 0.2065095 0.5510662 The number tells us the distribution of passengers from dataset train is: class-1, 24.24%; class-2, 20.65% and class-3 has 55.1%. The passenger’s distribution among the three classes given by dataset test: # Test data passenger distribution on classes. prop.table(table(as.factor(test$Pclass))) ## ## 1 2 3 ## 0.2559809 0.2224880 0.5215311 Lastly, the passenger distribution from dataset test are: 25.6% in class-1, 22.24% in class-2 and 52.15% percent in class-3. We can see that the distribution of passengers, in terms of percentage, among the three classes are almost identical both in order and in proportion. That is the most passenger are in class-3, then class-1 and finally class-2. Let us look into death and survive distribution among the three classes3, # Calculate death distribution across classes with Train data SurviveOverClass &lt;- table(train$Pclass, train$Survived) # Convert SurviveOverClass into data frame SoC.data.fram &lt;- data.frame(SurviveOverClass) # Retrieve death distribution in classes Death.distribution.on.class &lt;- SoC.data.fram$Freq[SoC.data.fram$Var2==0] prop.table(Death.distribution.on.class) ## [1] 0.1457195 0.1766849 0.6775956 These numbers tell us the distribution of death among the three classes are: 14.57% death from class-1, 17.66% from class-2 and 67.75% death from class-3. Similarly, we can calculate survive distribution among the three classes, # calculate survive distribution among the three classes Survive.distribution.on.class &lt;- SoC.data.fram$Freq[SoC.data.fram$Var2==1] prop.table(Survive.distribution.on.class) ## [1] 0.3976608 0.2543860 0.3479532 The results tell us that 39.76% of survived passenger are from class-1, and 25.43% from class-2, and 34.79% from class-3. Let us thinking about this numbers. Class-3 has 55.1% of passenger distribution but has 34.79% passenger survival distribution. Clearly, the survive rate in class-3 is lower than other two classes. It is equivalent to say, the survival chances of a passenger who is in class-1 are higher than who is a class-2 and class-3. Do it yourself: Calculate the Survival rate among the three classes. What conclusion you have by compare them? Numbers are good to provide summary and test some assumptions. Analyzing given data by means of statistical summary and other numbering methods is called Descriptive analysis. See section ?? . Perhaps, it is a good time to introduce Exploratory analysis, on the contrast with the Descriptive analysis, it uses graphical tools to explore the inside of given datasets. To do so, we need to import some useful graphical tools provided by R community. We can then use them to plot Survived as an factor on Pclass numbers. # Load up ggplot2 package to use for visualizations library(ggplot2) ## Warning: package &#39;ggplot2&#39; was built under R version 3.6.3 ggplot(train, aes(x = Pclass, fill = factor(Survived))) + geom_bar(width = 0.3) + xlab(&quot;Pclass&quot;) + ylab(&quot;Total Count&quot;) + labs(fill = &quot;Survived&quot;) Figure 4.6: Total count and survive rate of passenger on Pcalss. Graph is better, isn’t it? It is very intuative. Let’s briefly interpret this graph. The graph shown 4.6 tells us that the survive rate in Class-3 is the worst, and followed by class-2 and lastly, class-1. More people perished in the class-3 than any other two classes. It provides an important point that the chance of survive is associated with the social glass, if we can prove the Class-3 ticket is cheaper. To sum up the analysis with Pclass, We have used both Descriptive analysis and Exploratory analysis. The results suggested that the Pclass has a strong relation with death rate. That is passengers in Class-3 have a higher chance of death. The correlation with social class (richer or poor) is waiting to be proved if the class-3 ticket is cheaper than others. 4.5.4 Name Name attribute by definition shows peoples’ name. It should not have any impact on passengers’ live and death. Never heard of someone was survived because one’s name! However we still need to asess its quality. Fir Firstly, you may notice that the type of Name is a Factor, which is contradicted with the conventional understanding that name is a string or a list characters. Type chr would be more appropriate. Change its type to chr will help us to apply character functions to it and get it contents easily. Factor shows the uniqueness. it could help us to assess if there is missing value or duplicated values. Notice that attribute Name only has 1307 levels (can be observed from the data structure on the WorkSpace pane). In addition, the data summary, see Figure ??, not only confirmed this but also identified the two shorts because of the value “Connolly, Miss. Kate” and “Kelly, Mr. James” have been repeated twice each. Let us explore Name values in details. Firstly, let us convert Name type into chr. Then we can check duplicated names using which function in R to get the duplicate names and store them into a vector dup.names. And echo them out. # Convert Name type data$Name &lt;- as.character(data$Name) # Find the two duplicate names # First used which function to get the duplicate names and store them as a vector dup.names # check it up ?which. dup.names &lt;- data[which(duplicated(data$Name)), &quot;Name&quot;] # Echo out dup.names ## [1] &quot;Kelly, Mr. James&quot; &quot;Connolly, Miss. Kate&quot; Our code confirmed that the two duplicated names are indeed \"“Kelly, Mr. James” and “Connolly, Miss. Kate”. It comes no surprise that the both names are pretty common in UK and USA. One discovery though is that the names appeared has a title in it! Mr. is used in Kelly James and Miss. is used in Connolly Kate. This could be interesting. We can leave this for Preprocess to explore more. For the quality assessment it is mission accomplished. 4.5.5 Sex Sex attribute value assessment is simple. Its type Factor helps a lot. Since it only has two values “male” and “female”, we could easily check if there are missing values and any errors. # Use summary to check numbers and distribution summary(data$Sex) ## female male ## 466 843 # If you prefer you can use data.table functions It is obvious that there is no error and missing values. The result confirms this: male 843 and female 466, together we have 1309 passengers, which is the total numbers of the passenger. It is also simple to explore the relationship between gender and the survival rate. We had an assumption that the male passengers have a high death rate. We have plot tools in our disposal, let’s make use of it. Since only dataset train has the values on Survived, it makes sense that we only plot relation between gender and survival on dataset train. # plot Survived over Sex on dataset train ggplot(data[1:891,], aes(x = Sex, fill = Survived)) + geom_bar(width = 0.3) + xlab(&quot;Sex&quot;) + ylab(&quot;Total Count&quot;) + labs(fill = &quot;Survived&quot;) Figure 4.7: Total count and survive rate of passenger on sex. The graph shows that the male death rate is much higher than female passengers. Thinking: We have used data[1:891,] in our ggplot code. Why we do not use dataset train instead? What are the differnce if there is any? 4.5.6 Age To examine values of attribute Age, we do this, # Examine Age over data, train and test. summary(data$Age) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 0.17 21.00 28.00 29.88 39.00 80.00 263 summary(train$Age) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 0.42 20.12 28.00 29.70 38.00 80.00 177 summary(test$Age) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 0.17 21.00 27.00 30.27 39.00 76.00 86 These summary tell us that the minimum, median, mean, maximum and missing values (as NA). They are useful. but they failed telling us on the value distribution. Figure 4.8: Age summary as categorical data. From Figure 4.8, we can see a few problems: Age values have decimal point which is a sort of surprise and not sure if it is a mistake. There are large number of missing values: 177 missing value in dataset train and 86 missing value in dataset test, in total of 263, which count as 263/1309 = 20%. large number of missing values sets up a task for data preprocess to deal with. In the same time, it make you think whether it is a valid predictor or not. We can assess its impact on survive rate. So we need to look into dataset train. # plot distribution of age group ggplot(data, aes(x = Age)) + geom_histogram(binwidth = 10, fill=&quot;steelblue&quot;) + xlab(&quot;Age&quot;) + ylab(&quot;Total Count&quot;) ## Warning: Removed 263 rows containing non-finite values (stat_bin). # plot Survived on age group using train dataset ggplot(data[1:891,], aes(x = Age, fill = Survived)) + geom_histogram(binwidth = 10) + xlab(&quot;Age&quot;) + ylab(&quot;Total Count&quot;) ## Warning: Removed 177 rows containing non-finite values (stat_bin). Figure 4.9: Age ditribution and its Survive rate of passenger The graph shows the relationship between Age and survival rate. It becomes apparent that age group between 15 and 25 has the worst survival rate. It is also interesting to know that there are some age has values less than 0! With this, we could conclude that. The attribute Age has a serious quality problem: some age values are negative and large number 177 values are missing. If it is to be used as a predictor in our model for prediction, it needs a lot of work in the stage of preprocess. 4.5.7 SibSp Attribute SibSp represents passenger’s siblings and sprouts who travels with the passenger. We will a have pretty good idea about its values. This will help us to spot any errors and missing values. We do this, ### Exam SibSp, Its original type is int summary((data$SibSp)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0000 0.0000 0.0000 0.4989 1.0000 8.0000 # How many possible unique values? length(unique(data$SibSp)) ## [1] 7 #is there an y missing values? check the total number length(data$SibSp) ## [1] 1309 # Treat it as a factor, so we know the value distribution data$SibSp &lt;- as.factor(data$SibSp) summary(data$SibSp) ## 0 1 2 3 4 5 8 ## 891 319 42 20 22 6 9 The results have provided us with good evidence for access its values. Firstly, we know the minimum value is 0, and there are 891 records have 0 values. It means that there are 891 passenger who travel without siblings and sprouts; secondly, apart from the value 0, the 3 quarters of the passenger who has 1 company; and lastly the maximum number of the company a passenger had is 8. There are 9 of them. There are totally 7 kinds of company in terms of the numbers of company a passenger can have. It has not error or missing value since the total number are correct. We can assess its prediction power by looking into the relationship between SibSp and Suvivied, # plot entire SibSp distribution among the 7 values ggplot(data, aes(x = SibSp)) + geom_bar(width = 0.5) + xlab(&quot;SibSp&quot;) + ylab(&quot;Total Count&quot;)+ coord_cartesian() # Plot on the survive on SibSp ggplot(data[1:891,], aes(x = SibSp, fill = Survived)) + geom_bar(width = 0.5) + xlab(&quot;SibSp&quot;) + ylab(&quot;Total Count&quot;) + labs(fill = &quot;Survived&quot;) Figure 4.10: Plot SibSp distribution among the 7 values and its survive rate. We run two plots: the first one is the value distribution on entire dataset to have an impression on its distribution shape; and the second one is checking the survival rate over its distribution groups by dataset train. It seems that passenger who have two companies tend to have a better survival rate. This could be an interesting pattern to explore. Do it yourself: Calculate the Survival rate among the 7 possibilities in terms of have siblings or sprouds treval with them. What conclusion you have by compare them? We can conclude that the value of SibSp have a pretty good quality and there is no apparent error and missing values. Its predication power needs further investigation but it is informative. 4.5.8 Parch Attribute Parch, similar with SibSp, is representing the travel company or groups. Parch specifically represents parents or children. I don’t know why Kaggle separate them but it seems reasonable to think they together represent one thing that is “travel with family”. To access its value, we will do the same as we did on SibSp. ### Exam Parch, Its original type is int summary((data$Parch)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.000 0.000 0.000 0.385 0.000 9.000 # How many possible unique values? length(unique(data$Parch)) ## [1] 8 #is there an y missing values? check the total number length(data$Parch) ## [1] 1309 # Treat it as a factor, so we know the value distribution data$Parch &lt;- as.factor(data$Parch) summary(data$Parch) ## 0 1 2 3 4 5 6 9 ## 1002 170 113 8 6 6 2 2 The discovery is similar again with SibSp, that is: 1. The minimum value is 0, and there are 1002 records have 0 values. It means that there are 1002 passenger who travel without without parents or children (we still cannot see the passenger travel alone, he or she could travel with a sibling or a sprout, However, this rise an idea to look into passenger who travel alone, which means no sibling, sprout, parents and children.); 2. The maximum number is 9. There are 2 of them. 3. Apart from the value 0, the largest company number is 1. There are 170. 4. There are totally 8 possibilities in terms of the numbers of company a passenger can have. 5. It has not error or missing value since the total number are correct. We can assess its prediction power too by looking into the relationship between Parch and Survived, # plot entire Parch distribution among the 7 values ggplot(data, aes(x = Parch)) + geom_bar(width = 0.5) + xlab(&quot;Parch&quot;) + ylab(&quot;Total Count&quot;)+ coord_cartesian() # Plot on the survive on Parch ggplot(data[1:891,], aes(x = Parch, fill = Survived)) + geom_bar(width = 0.5) + xlab(&quot;Parch&quot;) + ylab(&quot;Total Count&quot;) + labs(fill = &quot;Survived&quot;) Figure 4.11: Plot Parch distribution among the 8 values and its survive rate. The plot shows us that it is definitely have impact on survival. But it i snot clear the prediction power in comparison with SibSp. I am not sure there are difference between “travel with parents or children” and “travel with siblings and sprout”. In addition, value 0 in each attributes does not excludes other attributes. Travel without parents or children does not mean travel without siblings or sprout. If we try to see the impact on survived in terms travel alone or with a company, we need to re-engineer these attributes. It is a good point anyway and give another task for data preprocess to do. 4.5.9 Ticket Intuitively, as mentioned before, ticket number like passenger names, should not be considered as bounded with the survival of a passenger. Unless the ticket number has other hidden information such as class or location on the boat. Bearing this in mind, let us assess its value. head(summary(data$Ticket),50) ## CA. 2343 1601 CA 2144 3101295 347077 ## 11 8 8 7 7 ## 347082 PC 17608 S.O.C. 14879 113781 19950 ## 7 7 7 6 6 ## 347088 382652 113503 16966 220845 ## 6 6 5 5 5 ## 349909 4133 PC 17757 W./C. 6608 113760 ## 5 5 5 5 4 ## 12749 17421 230136 24160 2666 ## 4 4 4 4 4 ## 36928 C.A. 2315 C.A. 33112 C.A. 34651 LINE ## 4 4 4 4 4 ## PC 17483 PC 17755 PC 17760 SC/Paris 2123 W./C. 6607 ## 4 4 4 4 4 ## 110152 110413 11767 13502 19877 ## 3 3 3 3 3 ## 19928 230080 239853 248727 248738 ## 3 3 3 3 3 ## 26360 2650 2653 2661 2662 ## 3 3 3 3 3 # Take a look at the ticket value str(data$Ticket) ## Factor w/ 929 levels &quot;110152&quot;,&quot;110413&quot;,..: 524 597 670 50 473 276 86 396 345 133 ... which(is.na(data$Ticket)) ## integer(0) The value of Ticket appears has no missing value and there are 929 different numbers and some with letters and some with special characters like “.” and “/”. There is no immediately apparent structure in the data. Let us plot them and also see if there is any pattern with survival. #plot it value ggplot(data[1:891,], aes(x = Ticket)) + geom_bar() + xlab(&quot;Ticket&quot;) + ylab(&quot;Total Count&quot;) # Plot on the survive on Ticket ggplot(data[1:891,], aes(x = Ticket, fill = Survived)) + geom_bar() + xlab(&quot;Ticket Number&quot;) + ylab(&quot;Total Count&quot;) + labs(fill = &quot;Survived&quot;) Figure 4.12: Plot of Ticket distribution and survival rate. The same tickets number has such a small number. It does not have any statistical meaning. It is possible to reengineer ticket number into groups like “number only” vs “with letter” or “with special characters”, or simply group them with the length of the ticket or with the initials, etc. There is a lot of thing you can do to see if there is any patterns connected with the survival. Over all, Ticket has a good quality and has no missing value and errors (we dont count repeated ticket number is an error). However, there is no obvious relations with the survive rate. 4.5.10 Fare The value of Fare are expected associated with “passenger’s wealth”. You would naturally associate its value with cabin condition and perhaps location of he cabin. Let us assess its value quality. summary(data$Fare) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 0.000 7.896 14.454 33.295 31.275 512.329 1 length(unique(data$Fare)) ## [1] 282 The initial assessment tells us that: 1. The value of Fare has one missing value. 2. They are 282 different prices among 1308 tickets. 3. The minimum value is 0 (Free ride?) and the maximum value is 512.329. 4. The mean value is 33.295 and the median is only 14.454. 5. There are two potential issues in here: 512.329 is extremely higher than others, it could be considered as an outlier or an error; another potential issue is the precision. Any currency cannot have a physical money which carry value three digits after the decimal point. so any value has three digits after decimal point could be an error. Let us examine the prediction power of attribute Fare. ggplot(data, aes(x = Fare)) + geom_histogram(binwidth = 5) + ggtitle(&quot;Fare Distribution&quot;) + xlab(&quot;Fare&quot;) + ylab(&quot;Total Count&quot;) + ylim(0,200) ## Warning: Removed 1 rows containing non-finite values (stat_bin). ## Warning: Removed 1 rows containing missing values (geom_bar). # Let&#39;s check to see if fare has predictive power ggplot(data[1:891,], aes(x = Fare, fill = Survived)) + geom_histogram(binwidth = 5) + xlab(&quot;Fare&quot;) + ylab(&quot;Total Count&quot;) + ylim(0,50) + labs(fill = &quot;Survived&quot;) ## Warning: Removed 6 rows containing missing values (geom_bar). Figure 4.13: Plot of Fare distribution and survival rate. It is not clear about Fare prediction power. One thing is clear that to be useful for predcition, Fare needs more engineer such as group it in different groups like &lt;5, 5 to 10, 10 to 15, …, etc. 4.5.11 Cabin Cabin has a large number of missing values as we noticed from the beginning of this section 4.5. So its quality is expected to be bed. let us find out how many missing values is the dataset train, so we can assess its predictive power over survive. Firstly, by looking into the structure of the dataset, # Examine cabin values str(data$Cabin) ## Factor w/ 187 levels &quot;&quot;,&quot;A10&quot;,&quot;A14&quot;,..: 1 83 1 57 1 1 131 1 1 1 ... # Cabin really isn&#39;t a factor, make a string and the display first 100 data$Cabin &lt;- as.character(data$Cabin) data$Cabin[1:100] ## [1] &quot;&quot; &quot;C85&quot; &quot;&quot; &quot;C123&quot; &quot;&quot; ## [6] &quot;&quot; &quot;E46&quot; &quot;&quot; &quot;&quot; &quot;&quot; ## [11] &quot;G6&quot; &quot;C103&quot; &quot;&quot; &quot;&quot; &quot;&quot; ## [16] &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; ## [21] &quot;&quot; &quot;D56&quot; &quot;&quot; &quot;A6&quot; &quot;&quot; ## [26] &quot;&quot; &quot;&quot; &quot;C23 C25 C27&quot; &quot;&quot; &quot;&quot; ## [31] &quot;&quot; &quot;B78&quot; &quot;&quot; &quot;&quot; &quot;&quot; ## [36] &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; ## [41] &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; ## [46] &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; ## [51] &quot;&quot; &quot;&quot; &quot;D33&quot; &quot;&quot; &quot;B30&quot; ## [56] &quot;C52&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; ## [61] &quot;&quot; &quot;B28&quot; &quot;C83&quot; &quot;&quot; &quot;&quot; ## [66] &quot;&quot; &quot;F33&quot; &quot;&quot; &quot;&quot; &quot;&quot; ## [71] &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; ## [76] &quot;F G73&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; ## [81] &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; ## [86] &quot;&quot; &quot;&quot; &quot;&quot; &quot;C23 C25 C27&quot; &quot;&quot; ## [91] &quot;&quot; &quot;&quot; &quot;E31&quot; &quot;&quot; &quot;&quot; ## [96] &quot;&quot; &quot;A5&quot; &quot;D10 D12&quot; &quot;&quot; &quot;&quot; we find out that Cabin is in a type of Factor and has 187 unique values with empty string \"\" and string start with letter like “A10”. By looking actual 100 values, we have a pretty good understand its contents. Notice that some string looks like multiple numbers, for instance “C23 C25 C27”, it is odd in comparison with others. let us have a close look at the dataset train and assess its prediction power. # Find out number of the missing value in the train train$Cabin &lt;- as.character(train$Cabin) # number of the missing value in the train table(train[which(train$Cabin ==&quot;&quot;), &quot;Cabin&quot;]) ## ## ## 687 # percentage of the missing value in the train table(train[which(train$Cabin ==&quot;&quot;), &quot;Cabin&quot;])/length(train$Cabin)*100 ## ## ## 77.10438 The above code tells us that in the dataset train, there are 687 missing value and it count as 71 percent of total value. This is significant number. Generally it will write off the attribute for any meaning for use. However, like its relation with survive with the consideration of the missing value. Since the small number of passenger in each cabin, we accumulate passenger with the first latter of the cabin number. That means we bin the passengers based on the first letter of their cabin number. Then we plot the survived number over the total number. # Take a look at just the first char as a factor and add to data as a new attribute data$cabin.first.char&lt;- as.factor(substr(data$Cabin, 1, 1)) # first cabin letter survival plot ggplot(data[1:891,], aes(x = cabin.first.char, fill = Survived)) + geom_bar() + xlab(&quot;First Cabin Letter&quot;) + ylab(&quot;Total Count&quot;) + ylim(0,750) + labs(fill = &quot;Survived&quot;) Figure 4.14: Plot of the passenger number and the survived number based on the first letter of their cabin number. To sumup, Cabin attribute has large number of missing value. The dataset train has 687 missing value and it counts as 71 percent of total value. Its prediction power is in serious doubt since it only has very small number for each cabin. To use it in any possible predictio model, it needs some re-engineering. 4.5.12 Embarkded Attribute Embarked records where a passenger get on board. From the Kaggle data description we know that there are three possible values for Embark — Southampton (S), Cherbourg (C), and Queenstown (Q). Let’s check the data quality. # Examine Embark values summary(data$Embarked) ## C Q S ## 2 270 123 914 length(data$Embarked) ## [1] 1309 The results confirms that there two missing values and three ports. Southampton as its initial depart port has largest passengers get on board. Let’s see its distribution and the survival rate. # Plot data distribution and the survival rate for analysis ggplot(data, aes(x = Embarked)) + geom_bar(width=0.5) + xlab(&quot;Passenger embarked port&quot;) + ylab(&quot;Total Count&quot;) ggplot(data[1:891,], aes(x = Embarked, fill = Survived)) + geom_bar(width=0.5) + xlab(&quot;Embarked port&quot;) + ylab(&quot;Total Count&quot;) + labs(fill = &quot;Survived&quot;) Figure 4.15: Plot of Embarked distribution and survival rate. The graph shows that about 70% of the people boarded from Southampton (914/1309 = 0.698). Just over 20% boarded from Cherbourg (270/1309 = 0.206) and the rest boarded from Queenstown about 10%. # Calculate death distribution over Embarked port with Train data # creat Embarked and Survived contingency table SurviveOverEmbarkedTable &lt;- table(train$Embarked, train$Survived) # Death-0/survived-1 value distribution (percentage) based on embarked ports # prop.table(mytable, 2) give us column (Survived) percentages Deathandsurvivepercentage &lt;- prop.table(SurviveOverEmbarkedTable, 2) # Plot M &lt;- c(&quot;c-Cherbourg&quot;, &quot;Q-Queenstown&quot;, &quot;S-Southampton&quot;) barplot(Deathandsurvivepercentage[2:4,1]*100, xlab =(&quot;&quot;), ylim=c(0,100), ylab=&quot;Death distribution in percentage %&quot;, names.arg = M, col=&quot;steelblue&quot;, main=&quot;Death distribution&quot;, border=&quot;black&quot;, beside=TRUE) barplot(Deathandsurvivepercentage[2:4,2]*100, xlab =(&quot;&quot;), ylim=c(0,100), ylab=&quot;Death distribution in percentage %&quot;, names.arg = M, col=&quot;blue&quot;, main=&quot;Death distribution&quot;, border=&quot;black&quot;, beside=TRUE) ## Calculate survived RATE distribution based on embarked ports # Death-0/survived-1 value distribution (percentage) based on embarked ports # prop.table(mytable, 1) give us row (Port) percentages # col-1 (Survived=0, perished) and col-2 (Survived =1, survived) DeathandsurviveRateforeachport &lt;- prop.table(SurviveOverEmbarkedTable, 1) #plot barplot(Deathandsurvivepercentage[2:4,1]*100, xlab =(&quot;&quot;), ylim=c(0,100), ylab=&quot;Death rate in percentage %&quot;, names.arg = M, col=&quot;red&quot;, main=&quot;Death rate comparison among mebarked ports&quot;, border=&quot;black&quot;, beside=TRUE) Figure 4.16: Plots of death distribution, survive distribution and death rate comparision over embarked port. The plot shows that both death and survive number distribution are similar. Southampton takes most death and survive portion because it has the largest number of passenger get on board, then Cherbourg, and last is Queenstown. However, in terms of death rate, which is the death/total from the passenger who get on board, southampton is the is the highest and then Queenstown, teh last is Cherbourg. That is to say, people who boarded from Cherbourg had a higher chance of survival than people who boarded from Southampton or Queenstown. In summary, we have explored all attributes through descriptive analysis, which is mainly using numbers and through exploratory analysis, which is using plot. We have examined the quality of each attributes by finding missing values and duplication. We have spoted some outliars and odd values. We have also assessed relationship between attribute Survived and all other attributes. The prediction power of each attributes have been understand to some extend. More prediction power study such as combination of two or three attributes are needed. The findings of each attributes provide tasks and goals for data preprocess step to accomplish. This code is not brilliant. It used many intermediate variables, you can check their structure and contents from WorkSpace pane. You can come up with a better code.↩︎ "],
["data-recods-level-assessment.html", "4.6 Data Recods Level Assessment", " 4.6 Data Recods Level Assessment Although we have examined the raw datasets records’ numbers in attributes level. We have a good knowledge about the record numbers in each given dataset. It is still necessary to check at the record level. It means if there some records have too many missing attributes’ value, for example, although some records have ids and may be names but most of the useful attributes’ value are missing. These records are bed or invalid records, should be removed or solve the missing values. On other hand some records have most attributes values are identical. These could be considered as duplicates. depends on the problem to be solved, they could be problematic and need to be dealt with. In our Titanic problem, record level assessment is not an issue. Since we have almost all the records are different. This does not mean we should completely ignore this step and doing the checking. "],
["summary.html", "Summary", " Summary All the analyses actions provide demonstrations how to access the raw data and understand their quantity and data quality. Notice that the understanding data is never a single one-off action. You never fully understood the given data. once the analytical process moving on, you may need to come back to apply some new decomposition on some attributes to explore more. Since our raw data is not too big in terms of both the number of records and the number of attributes. So it is relatively easy to assess their quality. In a real world project the raw data can be huge or can be too little. To perform an effective analysis you may need to reduce the data size or in other cases to increase the size. It means you need to do sampling on the given datasets and probably attributes selection too. Other cases you may need to create new attributes or combine a few attribute together. These are called attributes re-engineering. They are the part of important tasks in data preprocess , which is covered in the next chapter on data preprocess. The entire R code in this chapter is avalable in the file “TitanicDataAnalysis_UnderstandData.R” and it can be find in the appendix. "],
["exercises-4.html", "Exercises 4", " Exercises 4 Identify the code in this tutorial which can be conceptually categorized as Descriptive analysis and which one can be Exploratory analysis? Find out what is “rt” mean in R train &lt;- read.csv(\"train.csv\", header = TRUE) error message. Explore how to load files other than csv file. Explore load data through RStudio build-in functions. Check “File -&gt; Import Dataset”, also check how to load data from a databases like MySql. Calculate survival rate among the three Pclass. Calculate the percentage of survival among different SibSpand Parch groups. Plot distributions of Fare, Embarked of passengers who survived or did not survive Plot survival rate by Sex, Plot survival rate by Pclass, Plot survival rate by SibSp,Plot survival rate by Parch "]
]
